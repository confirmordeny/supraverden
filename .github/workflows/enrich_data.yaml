name: Enrich data with data from Wikidata

on:
  workflow_dispatch: 

permissions:
  contents: write 

jobs:
  enrich-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install pyyaml requests

      - name: Run Enrichment Script
        shell: python
        run: |
          import yaml
          import requests
          import sys
          import re
          import os
          import time

          # ================= CONFIGURATION =================
          TARGET_FILES = [
              'data/general_list.yaml',
              'data/united_nations.yaml'
          ]
          
          WIKIDATA_ENDPOINT = "https://query.wikidata.org/sparql"
          USER_AGENT = "SupraverdenBot/1.0 (github.com/confirmordeny/supraverden)"
          # =================================================

          def get_wikidata_data(q_code):
              time.sleep(1.0)
              query = f"""
              SELECT ?id ?name_fr ?name_es WHERE {{
                BIND(wd:{q_code} AS ?item)
                OPTIONAL {{ ?item wdt:P10632 ?id . }}
                OPTIONAL {{ ?item rdfs:label ?name_fr . FILTER(LANG(?name_fr) = "fr") }}
                OPTIONAL {{ ?item rdfs:label ?name_es . FILTER(LANG(?name_es) = "es") }}
              }}
              LIMIT 1
              """
              try:
                  response = requests.get(
                      WIKIDATA_ENDPOINT, 
                      params={'format': 'json', 'query': query}, 
                      headers={'User-Agent': USER_AGENT},
                      timeout=30
                  )
                  if response.status_code == 429:
                      time.sleep(10)
                      return None
                  if response.status_code != 200:
                      return None

                  data = response.json()
                  bindings = data.get('results', {}).get('bindings', [])
                  if not bindings:
                      return {}

                  result_row = bindings[0]
                  return {
                      'os_id': result_row.get('id', {}).get('value'),
                      'name_fr': result_row.get('name_fr', {}).get('value'),
                      'name_es': result_row.get('name_es', {}).get('value')
                  }
              except Exception as e:
                  print(f"    [!] Connection Exception: {e}")
                  return None

          def process_single_file(file_path):
              print(f"\n--- Processing {file_path} ---")
              if not os.path.exists(file_path):
                  return False

              with open(file_path, 'r', encoding='utf-8') as f:
                  original_content = f.read()

              # Preserve header comments
              header_match = re.match(r'^(\s*#.*|\s*\n)*', original_content)
              header_block = header_match.group(0) if header_match else ""

              try:
                  data = yaml.safe_load(original_content)
              except yaml.YAMLError as exc:
                  print(f"  [!] YAML Parsing Error: {exc}")
                  return False

              if not data:
                  return False

              updates_count = 0
              for name, info in data.items():
                  if not isinstance(info, dict) or 'Wikidata_code' not in info:
                      continue

                  w_code = str(info['Wikidata_code']).replace('[', '').replace(']', '').strip()
                  if
